| ğŸ“„ / ğŸ“                                                                                       | Description                                                                        |
| :-------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------- |
| **ğŸ“„ README.md**                                                                              | Main project documentation â€” explains setup, usage, and experiments.               |
| **ğŸ“„ requirements.txt**                                                                       | Python dependencies required for the project.                                      |
| **ğŸ“„ setup.py**                                                                               | Optional packaging file for `pip install -e .` (for local development).            |
|                                                                                               |                                                                                    |
| **ğŸ“ configs/**                                                                               | Centralized configuration files for models, datasets, estimators, and experiments. |
| â”œâ”€â”€ **base_config.yaml** â€” global defaults (device, logging, and sampling options).           |                                                                                    |
| â”œâ”€â”€ **model/** â€” defines LLM and entailment model settings (e.g., Llama-2, Mistral).          |                                                                                    |
| â”œâ”€â”€ **dataset/** â€” dataset-specific configs (TriviaQA, SQuAD, SVAMP, etc.).                   |                                                                                    |
| â”œâ”€â”€ **estimator/** â€” parameters for Bayesian, Histogram, and Rescaled estimators.             |                                                                                    |
| â””â”€â”€ **experiments/** â€” pre-defined setups for fixed/adaptive budget experiments.              |                                                                                    |
|                                                                                               |                                                                                    |
| **ğŸ“ data/**                                                                                  | Stores all data artifacts (prompts, generations, meaning mappings, and results).   |
| â”œâ”€â”€ **prompts/** â€” input prompts for the LLM.                                                 |                                                                                    |
| â”œâ”€â”€ **generations/** â€” generated sequences and their probabilities *p(sâ€–x)*.                  |                                                                                    |
| â”œâ”€â”€ **meanings/** â€” semantic class mappings obtained via entailment models.                   |                                                                                    |
| â””â”€â”€ **results/** â€” saved semantic entropy values, AUROC scores, and plots.                    |                                                                                    |
|                                                                                               |                                                                                    |
| **ğŸ“ src/**                                                                                   | Core implementation source code.                                                   |
| â”œâ”€â”€ **llm_interface.py** â€” handles LLM sampling and probability extraction.                   |                                                                                    |
| â”œâ”€â”€ **meaning_mapper.py** â€” clusters sequences into semantic meanings.                        |                                                                                    |
| â”œâ”€â”€ **data_utils.py** â€” helper functions for loading/saving datasets.                         |                                                                                    |
| â”œâ”€â”€ **train_prior.py** â€” learns prior distribution over meaning counts *K*.                   |                                                                                    |
| â”œâ”€â”€ **estimate_entropy.py** â€” main entry point for computing Bayesian semantic entropy.       |                                                                                    |
| â”œâ”€â”€ **adaptive_sampler.py** â€” dynamically allocates samples until target variance is reached. |                                                                                    |
| â”‚                                                                                             |                                                                                    |
| â”œâ”€â”€ **bayesian_estimator/** â€” core Bayesian entropy estimation logic.                         |                                                                                    |
| â”‚   â”œâ”€â”€ **dirichlet_entropy.py** â€” analytical Dirichlet expectation formulas.                 |                                                                                    |
| â”‚   â”œâ”€â”€ **truncated_dirichlet.py** â€” Monte Carlo integration with constraints.                |                                                                                    |
| â”‚   â”œâ”€â”€ **hierarchical_model.py** â€” Bayesian handling of unknown *K* values.                  |                                                                                    |
| â”‚   â”œâ”€â”€ **estimator.py** â€” integrates all modules into a single estimator class.              |                                                                                    |
| â”‚   â””â”€â”€ **utils.py** â€” mathematical helpers for entropy and sampling.                         |                                                                                    |
| â”‚                                                                                             |                                                                                    |
| â””â”€â”€ **evaluation/** â€” scripts for assessing estimator performance.                            |                                                                                    |
| Â Â Â Â â”œâ”€â”€ **metrics.py** â€” AUROC, F1, and statistical measures.                                 |                                                                                    |
| Â Â Â Â â”œâ”€â”€ **compare_baselines.py** â€” compares Bayesian estimator vs. baselines.                 |                                                                                    |
| Â Â Â Â â””â”€â”€ **visualize_results.py** â€” creates plots for performance comparison.                  |                                                                                    |
|                                                                                               |                                                                                    |
| **ğŸ“ experiments/**                                                                           | Reproducible scripts and notebooks for replicating paper results.                  |
| â”œâ”€â”€ **run_fixed_budget.py** â€” runs fixed-sample (N) experiments.                              |                                                                                    |
| â”œâ”€â”€ **run_adaptive_budget.py** â€” runs adaptive-sampling experiments.                          |                                                                                    |
| â””â”€â”€ **analyze_results.ipynb** â€” Jupyter notebook for analysis and visualization.              |                                                                                    |
|                                                                                               |                                                                                    |
| **ğŸ“ logs/**                                                                                  | Stores runtime and debugging logs.                                                 |
|                                                                                               |                                                                                    |
| **ğŸ“ tests/**                                                                                 | Unit and integration tests ensuring correctness and reproducibility.               |
| â”œâ”€â”€ **test_dirichlet_entropy.py**                                                             |                                                                                    |
| â”œâ”€â”€ **test_truncated_sampling.py**                                                            |                                                                                    |
| â””â”€â”€ **test_end_to_end.py**                                                                    |                                                                                    |







##############################################################################################################################################


# ğŸ“‚ Data Directory

This folder contains all datasets, model generations, semantic mappings, and entropy estimation results used in the **Bayesian Semantic Entropy** project.

Each subfolder represents a stage in the data pipeline â€” from prompts to final entropy outputs.

---

## ğŸ§­ Directory Structure

```
data/
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ triviaqa_prompts.json
â”‚   â”œâ”€â”€ squad_prompts.json
â”‚   â””â”€â”€ svamp_prompts.json
â”‚
â”œâ”€â”€ generations/
â”‚   â”œâ”€â”€ triviaqa/
â”‚   â”œâ”€â”€ squad/
â”‚   â””â”€â”€ svamp/
â”‚
â”œâ”€â”€ meanings/
â”‚   â”œâ”€â”€ triviaqa/
â”‚   â”œâ”€â”€ squad/
â”‚   â””â”€â”€ svamp/
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ entropy_estimates.csv
    â”œâ”€â”€ bayesian_vs_baselines.csv
    â””â”€â”€ figures/
```

---

## ğŸª¶ 1. `prompts/` â€” Input Questions or Contexts

Contains the **raw prompts** that the model will answer.

Example (`triviaqa_prompts.json`):

```json
[
  { "id": "tqa_001", "question": "What is the capital of France?" },
  { "id": "tqa_002", "question": "Who wrote the play Hamlet?" }
]
```

Used by: `src/llm_interface.py`

---

## ğŸ¤– 2. `generations/` â€” Model Responses

Stores **LLM-generated responses** for each prompt, along with optional log probabilities.

Example (`generations/triviaqa/sample_001.json`):

```json
{
  "id": "tqa_001",
  "prompt": "What is the capital of France?",
  "responses": [
    {"text": "Paris.", "logprob": -0.3},
    {"text": "The capital of France is Paris.", "logprob": -0.5}
  ]
}
```

Generated by: `src/llm_interface.py`

---

## ğŸ§  3. `meanings/` â€” Semantic Clusters

After generation, responses are grouped by **semantic equivalence** using an entailment model.

Example (`meanings/triviaqa/meanings_001.json`):

```json
{
  "id": "tqa_001",
  "prompt": "What is the capital of France?",
  "clusters": [
    {
      "meaning_id": 0,
      "members": [
        "Paris.",
        "The capital of France is Paris.",
        "It's Paris."
      ]
    }
  ]
}
```

Generated by: `src/meaning_mapper.py`

---

## ğŸ“Š 4. `results/` â€” Entropy & Evaluation Outputs

Contains computed **semantic entropy estimates**, baseline comparisons, and figures.

Example (`entropy_estimates.csv`):

| prompt_id | dataset  | estimator | E[h] | Var[h] | K_estimated | N_samples |
| --------- | -------- | --------- | ---- | ------ | ----------- | --------- |
| tqa_001   | triviaqa | bayesian  | 0.21 | 0.002  | 1           | 10        |
| tqa_002   | triviaqa | bayesian  | 0.48 | 0.005  | 3           | 12        |

Plots and comparison charts are saved in `results/figures/`.

Generated by:

* `src/estimate_entropy.py`
* `src/evaluation/compare_baselines.py`
* `src/evaluation/visualize_results.py`



## ğŸ§© Notes

* Keep raw data (prompts and generations) under version control only if small.
  Large datasets should be added to `.gitignore`.
* Use consistent prompt IDs across all files (`id` field must match).
* Store probabilities (`logprob`) whenever possible â€” they improve Bayesian truncation accuracy.

---

**Next step:** run `src/llm_interface.py` to populate the `generations/` folder with model outputs.




##############################################################################################################################################
